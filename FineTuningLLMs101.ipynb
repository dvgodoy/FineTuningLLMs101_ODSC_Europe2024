{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "xeKthJYgEQg_",
      "metadata": {
        "id": "xeKthJYgEQg_"
      },
      "source": [
        "![](https://raw.githubusercontent.com/dvgodoy/FineTuningLLMs101_ODSC_Europe2024/main/images/title.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mRrjIkhQEQhA",
      "metadata": {
        "id": "mRrjIkhQEQhA"
      },
      "source": [
        "## Who Am I?\n",
        "\n",
        "Data scientist, teacher, author of the ***Deep Learning with PyTorch Step-by-Step*** series.\n",
        "\n",
        "[![](https://raw.githubusercontent.com/dvgodoy/FineTuningLLMs101_ODSC_Europe2024/main/images/new_books.png)](https://pytorchstepbystep.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mJcITc7sEQhB",
      "metadata": {
        "id": "mJcITc7sEQhB"
      },
      "source": [
        "### Upcoming Book: A Short Guide to Fine-Tuning LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Qb09p005EQhC",
      "metadata": {
        "id": "Qb09p005EQhC"
      },
      "source": [
        "<center><a href=\"https://leanpub.com/finetuning\"><img src=\"https://raw.githubusercontent.com/dvgodoy/FineTuningLLMs101_ODSC_Europe2024/main/images/cover.png\" width=\"200\"/></a></center>\n",
        "<br>\n",
        "<center><a href=\"https://leanpub.com/finetuning\">leanpub.com/finetuning</a></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E2oovLQ2EQhD",
      "metadata": {
        "id": "E2oovLQ2EQhD"
      },
      "source": [
        "## Agenda\n",
        "\n",
        "- Why Fine-Tune?\n",
        "- Types of Fine-Tuning\n",
        "- The Main Challenge\n",
        "- Loading a Quantized Base Model\n",
        "- Formatting Your Dataset\n",
        "- Setting Up Low-Rank Adapters (LoRA)\n",
        "- Fine-Tuning with SFTTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XGGHYHAuEQhD",
      "metadata": {
        "id": "XGGHYHAuEQhD"
      },
      "source": [
        "## Why Fine-Tune?\n",
        "\n",
        "- Pretrained (base) models are **next word predictors**: they do not understand **questions** or **instructions** naturally.\n",
        "\n",
        "\n",
        "- If prompted with a question, a base model is likely to reply with even **more questions** insteaf of answers.\n",
        "\n",
        "\n",
        "- Fine-tuning can be used to:\n",
        "  - **change the behavior** of the model\n",
        "  - **change the style** of its answers\n",
        "  - **increase its knowledge**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "umVXbIp5EQhE",
      "metadata": {
        "id": "umVXbIp5EQhE"
      },
      "source": [
        "## Types of Fine-Tuning\n",
        "\n",
        "- **Self-supervised fine-tuning**: it works by training the model to predict the next word - just like in (base) model pretraining.\n",
        "  - it may be used to change **the style** of a model's answers to the user prompt\n",
        "  - in self-supervised fine-tuning, **the labels are the same as the inputs**, except that they are **shifted** by one position\n",
        "\n",
        "\n",
        "- **Supervised fine-tuning**: it works by training the model on **pairs of inputs/outputs** such as **question/answer** or **prompt/response**.\n",
        "  - it may be used to teach the model how to **respond to user prompts** related to a given **domain**\n",
        "\n",
        "\n",
        "- **Reinforcement-based fine-tuning**: it works by training the model on **labeled outputs** (good/bad or appropriate/inappropriate)\n",
        "  - it may be used to **align the model** or **improve its answers**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BZdYvjXsEQhE",
      "metadata": {
        "id": "BZdYvjXsEQhE"
      },
      "source": [
        "## The Main Challenge\n",
        "\n",
        "Fine-tuning LLMs feels like trying to fit this:\n",
        "\n",
        "![](https://raw.githubusercontent.com/dvgodoy/FineTuningLLMs101_ODSC_Europe2024/main/images/elephant.png)\n",
        "\n",
        "into this:\n",
        "\n",
        "![](https://raw.githubusercontent.com/dvgodoy/FineTuningLLMs101_ODSC_Europe2024/main/images/beetle.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YzcOwMvcEQhF",
      "metadata": {
        "id": "YzcOwMvcEQhF"
      },
      "source": [
        "### Attention Is All You Need\n",
        "\n",
        "- LLMs are Transformer Decoders\n",
        "- The majority of the model's parameters are in the attention heads\n",
        "\n",
        "![](https://raw.githubusercontent.com/dvgodoy/FineTuningLLMs101_ODSC_Europe2024/main/images/stacked_layers.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G48picD2EQhG",
      "metadata": {
        "id": "G48picD2EQhG"
      },
      "source": [
        "### We have MANY problems!\n",
        "\n",
        "1. Base model takes a lot of space (p)\n",
        "2. Optimizer's states (Adam) takes even more space (2p)\n",
        "3. Gradients take a lot of space (p)\n",
        "4. Activations take a lot of space, especially if the sequences are long\n",
        "5. Attention is quadratic on the sequence length (10x longer => 100x more expensive to handle)\n",
        "\n",
        "p = # of parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ekIGgo1PEQhG",
      "metadata": {
        "id": "ekIGgo1PEQhG"
      },
      "source": [
        "### Combine many solutions, we must!\n",
        "\n",
        "1. ~~Base model takes a lot of space (p)~~\n",
        "\n",
        "Solution: **Quantization** reduces the model's memory footprint.\n",
        "\n",
        "2. ~~Optimizer's states (Adam) takes even more space (2p)~~\n",
        "\n",
        "Solutions: While **8-bit Adam** may reduce the optimizer's memory footprint (especially if you're updating all parameters), **LoRA** drastically reduces the number of trainable parameters, thus making the optimizer a non-issue,\n",
        "\n",
        "3. ~~Gradients take a lot of space (p)~~\n",
        "\n",
        "Solutions: **Checkpointing** trades compute for memory (discarding and recomputing values as they are needed, instead of caching them) and **LoRA** reduces the number of trainable parameters, so fewer gradients are computed overall.\n",
        "\n",
        "4. ~~Activations take a lot of space, especially if the sequences are long~~\n",
        "\n",
        "Solution: **Checkpointing** once again trades compute for memory.\n",
        "\n",
        "5. ~~Attention is quadratic on the sequence length (10x longer => 100x more expensive to handle)~~\n",
        "\n",
        "Solution: **Flash Attention** removes several inefficiencies of the original implementation, thus making memory requirements **linearly** proportional to sequence length! However, it only works on higher-end GPUs (it won't work on Colab)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QeaxyMxIEQhG",
      "metadata": {
        "id": "QeaxyMxIEQhG"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "kODUm5BmEQhI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kODUm5BmEQhI",
        "outputId": "5a17ca8b-855a-4e55-b7a2-ab2af98d8906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting trl\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting peft\n",
            "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.2)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.3.1+cu121)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.32.1)\n",
            "Collecting tyro>=0.5.11 (from trl)\n",
            "  Downloading tyro-0.8.8-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Downloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading tyro-0.8.8-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m137.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: xxhash, shtab, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, matplotlib, tyro, nvidia-cusolver-cu12, transformers, datasets, bitsandbytes, trl, peft\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.43.3 datasets-2.21.0 dill-0.3.8 matplotlib-3.9.2 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 peft-0.12.0 pyarrow-17.0.0 shtab-1.7.1 transformers-4.44.0 trl-0.9.6 tyro-0.8.8 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers datasets trl bitsandbytes peft matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "LE3FafblEQhI",
      "metadata": {
        "id": "LE3FafblEQhI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from datasets import load_dataset\n",
        "from trl import SFTConfig, SFTTrainer, setup_chat_format\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BGxWM_J9EQhJ",
      "metadata": {
        "id": "BGxWM_J9EQhJ"
      },
      "source": [
        "## Loading a Quantized Based Model\n",
        "\n",
        "### Model's Parameters (FP32)\n",
        "\n",
        "![](https://raw.githubusercontent.com/dvgodoy/FineTuningLLMs101_ODSC_Europe2024/main/images/quant1.png)\n",
        "Source:[Quantization Fundamentals with Hugging Face](https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face/)\n",
        "\n",
        "### Quantizing Parameters (FP32 -> INT8)\n",
        "![](https://raw.githubusercontent.com/dvgodoy/FineTuningLLMs101_ODSC_Europe2024/main/images/quant2.png)\n",
        "Source:[Quantization Fundamentals with Hugging Face](https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "xbPZQ4aNEQhJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbPZQ4aNEQhJ",
        "outputId": "e0bc0d27-6502-4148-cf5a-0763617f0ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                             quantization_config=bnb_config\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8AOI2ZnmFdzH",
      "metadata": {
        "id": "8AOI2ZnmFdzH"
      },
      "source": [
        "The quantized model takes up roughly 360 Mb or RAM, which is a little bit over 1/4 of its original size (1324 Mb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5WXLJ9QNEQhJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WXLJ9QNEQhJ",
        "outputId": "3a3c1971-6677-4606-d8e2-9fe8c3b4a22e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "359.354368\n"
          ]
        }
      ],
      "source": [
        "print(model.get_memory_footprint()/1e6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3gAVQKRsFHpt",
      "metadata": {
        "id": "3gAVQKRsFHpt"
      },
      "source": [
        "Notice that all `Linear` layers were replaced by their `Linear8bitLt` quantized versions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "Oe2hIoBbEQhJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe2hIoBbEQhJ",
        "outputId": "cbc3114f-2609-4c02-e429-8f4ddc1a2ad5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OPTForCausalLM(\n",
              "  (model): OPTModel(\n",
              "    (decoder): OPTDecoder(\n",
              "      (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
              "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
              "      (project_out): Linear8bitLt(in_features=1024, out_features=512, bias=False)\n",
              "      (project_in): Linear8bitLt(in_features=512, out_features=1024, bias=False)\n",
              "      (layers): ModuleList(\n",
              "        (0-23): 24 x OPTDecoderLayer(\n",
              "          (self_attn): OPTAttention(\n",
              "            (k_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): ReLU()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear8bitLt(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear8bitLt(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=50272, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sG1A7Y6sEQhJ",
      "metadata": {
        "id": "sG1A7Y6sEQhJ"
      },
      "source": [
        "## Formatting Your Dataset\n",
        "\n",
        "<center><a href=\"https://imgflip.com/i/90l40r\"><img src=\"https://i.imgflip.com/90l40r.jpg\" title=\"made at imgflip.com\"/></a><div></div></center>\n",
        "\n",
        "The `SFTTrainer` we'll use later can handle a couple of default formats, namely:\n",
        "- conversational format\n",
        "\n",
        "```{\"messages\": [\n",
        "    {\"role\": \"system\", \"content\": \"You are helpful\"},\n",
        "    {\"role\": \"user\", \"content\": \"What's the capital of France?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"...\"}\n",
        "]}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lPKb-T0vEQhL",
      "metadata": {
        "id": "lPKb-T0vEQhL"
      },
      "source": [
        "- instruction format\n",
        "\n",
        "```\n",
        "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
        "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
        "```\n",
        "\n",
        "So, to make it easier to train, we're renaming the columns accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "qc6YWqEiEQhL",
      "metadata": {
        "id": "qc6YWqEiEQhL"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"dvgodoy/yoda_sentences\", split=\"train\")\n",
        "dataset = dataset.rename_column(\"sentence\", \"prompt\")\n",
        "dataset = dataset.rename_column(\"translation_extra\", \"completion\")\n",
        "dataset = dataset.remove_columns([\"translation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ApOxKdy1EQhL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApOxKdy1EQhL",
        "outputId": "7e9d6c7f-6901-492e-cf14-2fd607e11862"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': 'The birch canoe slid on the smooth planks.',\n",
              " 'completion': 'On the smooth planks, the birch canoe slid. Yes, hrrrm.'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eB6dPZyrEQhL",
      "metadata": {
        "id": "eB6dPZyrEQhL"
      },
      "source": [
        "### Tokenizer\n",
        "\n",
        "The tokenizer is an important piece of the process.\n",
        "\n",
        "If we don't get the special tokens right, the model will either generate gibberish or be an annoying chatterbox.\n",
        "\n",
        "A few important things to remember:\n",
        "\n",
        "1. If you're padding, you should use **left** padding.\n",
        "\n",
        "  - left-padding: `<|pad|><|pad|><|pad|>This is a short sentence.</s>`\n",
        "\n",
        "  - right-padding: `This is a short sentence.<|pad|><|pad|><|pad|></s>`\n",
        "  \n",
        "Remember, LLMs are **decoders**, they predict the **next word** at the **end of the sentence**.\n",
        "\n",
        "Right-padding makes it too easy for the LLM to generate endless sequences of `<|pad|>` tokens.\n",
        "\n",
        "You do not want that.\n",
        "\n",
        "2. **DO NOT** set the **padding token** to be the same as the **EOS (ending) token**.\n",
        "\n",
        "  - proper padding token: `<|pad|><|pad|><|pad|>This is a short sentence.</s>`\n",
        "\n",
        "  - EOS as padding token: `</s></s></s>This is a short sentence.</s>`\n",
        "\n",
        "Using the EOS token as padding token **will** confuse the model, as it will learn that there may be more words after the EOS token (because **there are** words after the left-padded tokens.\n",
        "\n",
        "You do no want that either."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ZFvf8h3PEQhM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFvf8h3PEQhM",
        "outputId": "e312eb2b-02d1-4466-af1b-858a57a221af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model.config._name_or_path,\n",
        "    padding_side='left',\n",
        "    pad_token='<|pad|>',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "rLQwbN-tEQhM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLQwbN-tEQhM",
        "outputId": "66187b86-9427-4437-fc04-3940eda0eec9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<|pad|>', '</s>', '</s>')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tokenizer.pad_token, tokenizer.eos_token, tokenizer.bos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oUon5tuFEQhN",
      "metadata": {
        "id": "oUon5tuFEQhN"
      },
      "source": [
        "Now that we have both model and tokenizer, we can take them for a spin and use them to generate a few words.\n",
        "\n",
        "Notice that it still is the base pretrained model. It does not know instructions, and it does not know Yoda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8KXn65I1EQhN",
      "metadata": {
        "id": "8KXn65I1EQhN"
      },
      "outputs": [],
      "source": [
        "def generate(model, tokenizer, prompt, max_new_tokens=100):\n",
        "    tokenized_input = tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
        "    input_ids = tokenized_input[\"input_ids\"].cuda()\n",
        "\n",
        "    model.eval()\n",
        "    generation_output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        num_beams=3,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        repetition_penalty=1.1,\n",
        "        do_sample=True, top_p=0.9,temperature=0.95,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "    output = tokenizer.batch_decode(generation_output, skip_special_tokens=False)[0]\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ZK5iBB_YEQhN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK5iBB_YEQhN",
        "outputId": "a48fba2c-2282-4d23-e0d2-61eca61387f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Force is strong in you!”\n",
            "\n",
            "“It’s not,” I said. “I don’t think I’ve ever been so angry at myself.”\n",
            "\n",
            "“I know,” he said. “I’ve never been so angry at myself.”\n",
            "\n",
            "“But you’ve never been so angry at yourself,” I said.\n",
            "\n",
            "“No,” he said. “I\n"
          ]
        }
      ],
      "source": [
        "print(generate(model, tokenizer, 'The Force is strong in you!'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oU1xh_p2EQhN",
      "metadata": {
        "id": "oU1xh_p2EQhN"
      },
      "source": [
        "#### Chat Template\n",
        "\n",
        "We're trusting that `SFTTrainer` will handle our dataset appropriately, since we renamed the columns accordingly.\n",
        "\n",
        "It **will**, but **only** if the provided tokenizer has a **chat template**, that is, if it specifies the following:\n",
        "\n",
        "- which special tokens should be used and where they should be placed\n",
        "- where the specified columns (`prompt` and `completion`) should be placed\n",
        "- what is the **generation prompt** (more on that in the last section)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "yBz3gESEEQhO",
      "metadata": {
        "id": "yBz3gESEEQhO"
      },
      "outputs": [],
      "source": [
        "tokenizer.chat_template"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BsdyWmvhEQhO",
      "metadata": {
        "id": "BsdyWmvhEQhO"
      },
      "source": [
        "Unfortunately, our model/tokenizer does not come with a chat template.\n",
        "\n",
        "It makes sense, since the base model was not fine-tuned for instructions.\n",
        "\n",
        "However, we can define a template or, better yet, use [ChatML](https://github.com/openai/openai-python/blob/release-v0.28.0/chatml.md) as default template calling the `setup_chat_format()` function.\n",
        "\n",
        "**IMPORTANT #1**: the `setup_chat_format()` function forcibly resize the embedding layers to match the tokenizer's vocabulary length. However, most models have **spare space** in their embedding layers, meaning it is possible to **add extra tokens without resizing the embedding layers**. For performance reasons, it is commonplace to keep the embedding layer's length as a multiple of a power of 2 (that's what we're doing in the `resize_to_multiple_of` argument since our model's embedding layer has 50,272 elements while the tokenizer has only 50,266).\n",
        "\n",
        "**IMPORTANT #2**: if your model's embedding layer gets resized (whether it's shorter or longer than it was), you'll **have to save the embeddings** after fine-tuning, thus making your adapter larger, and requiring extra steps for loading it afterward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "zganniuMEQhO",
      "metadata": {
        "id": "zganniuMEQhO"
      },
      "outputs": [],
      "source": [
        "if tokenizer.chat_template is None:\n",
        "    model, tokenizer = setup_chat_format(model, tokenizer, resize_to_multiple_of=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "eaFzgM-BEQhP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaFzgM-BEQhP",
        "outputId": "b183a246-3c05-4754-821b-e533734ab3de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<|im_end|>', '<|im_end|>', '<|im_start|>')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tokenizer.pad_token, tokenizer.eos_token, tokenizer.bos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mWwVt5XyEQhP",
      "metadata": {
        "id": "mWwVt5XyEQhP"
      },
      "source": [
        "Uh-oh! Unfortunately, the function does exactly what I advised you **not** to do: the padding token was set to be the same as the EOS token.\n",
        "\n",
        "Let's fix it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "CHKAnuFVEQhP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHKAnuFVEQhP",
        "outputId": "31112fbe-0116-4e44-85ea-54971914e46d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<|pad|>', '<|im_end|>', '<|im_start|>')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tokenizer.pad_token = '<|pad|>'\n",
        "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
        "\n",
        "tokenizer.pad_token, tokenizer.eos_token, tokenizer.bos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZJI9MEzKEQhP",
      "metadata": {
        "id": "ZJI9MEzKEQhP"
      },
      "source": [
        "Now, let's see how it will format an example from our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6-mbEiKCEQhQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-mbEiKCEQhQ",
        "outputId": "48c7090f-20e1-4859-9a9e-a5b5be64d0ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>user\n",
            "The birch canoe slid on the smooth planks.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "On the smooth planks, the birch canoe slid. Yes, hrrrm.<|im_end|>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": dataset[0]['prompt']},\n",
        "    {\"role\": \"assistant\", \"content\": dataset[0]['completion']}\n",
        "]\n",
        "print(tokenizer.apply_chat_template(messages, tokenize=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kBBVuIJMGZck",
      "metadata": {
        "id": "kBBVuIJMGZck"
      },
      "source": [
        "Notice that each interaction is wrapped in `<|im_start|>` and `<im_end|>` tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y8d-t3p-EQhQ",
      "metadata": {
        "id": "Y8d-t3p-EQhQ"
      },
      "source": [
        "## Setting Up Low-Rank Adapters (LoRA)\n",
        "\n",
        "### What is LoRA?\n",
        "\n",
        "LoRA is a **parameter-efficient fine-tuning (PEFT)** technique that attaches **adapters** to linear layers (mostly in attention heads) to allow models to be fine-tuned without updating the base model's parameters.\n",
        "\n",
        "![](https://raw.githubusercontent.com/dvgodoy/FineTuningLLMs101_ODSC_Europe2024/main/images/lora.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "W9nDboWaEQhQ",
      "metadata": {
        "id": "W9nDboWaEQhQ"
      },
      "outputs": [],
      "source": [
        "# Without LoRA\n",
        "def regular_forward_matmul(x, W):\n",
        "    h = x @ W\n",
        "    return h\n",
        "\n",
        "# With LoRA\n",
        "def lora_forward_matmul(x, W, W_A, W_B, alpha):\n",
        "    h = x @ W\n",
        "    h += x @ (W_A @ W_B)*alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DHWoE-T6EQhQ",
      "metadata": {
        "id": "DHWoE-T6EQhQ"
      },
      "source": [
        "$$\n",
        "\\Large\n",
        "W_{\\text{LoRA}} = W_{\\text{orig}}+\\frac{\\alpha}{r}\\Delta W = W_{\\text{orig}}+\\frac{\\alpha}{r}BA\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MFtd62eHEQhQ",
      "metadata": {
        "id": "MFtd62eHEQhQ"
      },
      "source": [
        "![](https://raw.githubusercontent.com/dvgodoy/FineTuningLLMs101_ODSC_Europe2024/main/images/lora_diagram.png)\n",
        "Source: [PEFT documentation](https://huggingface.co/docs/peft/main/en/conceptual_guides/lora#merge-lora-weights-into-the-base-model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KZkjaHKkEQhR",
      "metadata": {
        "id": "KZkjaHKkEQhR"
      },
      "source": [
        "### PEFT\n",
        "\n",
        "It is a library for efficiently adapting large pretrained models. It is integrated with the Transformers, Diffusers, and Accelerate libraries.\n",
        "\n",
        "#### Steps:\n",
        "\n",
        "1. Instantiate a base model (done!)\n",
        "2. Create an instance of the configuration ([`LoraConfig`](https://huggingface.co/docs/peft/main/en/conceptual_guides/lora#common-lora-parameters-in-peft)) object (cell below)\n",
        "3. Apply the LoRA configuration to the base model using the `get_peft_model()` method (cell below)\n",
        "4. Train the PEFT model as you would normally train any other model (next section)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ilxMPNXDEQhR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilxMPNXDEQhR",
        "outputId": "af1841dc-2845-4625-99a7-c57a8f11670d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): OPTForCausalLM(\n",
              "      (model): OPTModel(\n",
              "        (decoder): OPTDecoder(\n",
              "          (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
              "          (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
              "          (project_out): Linear8bitLt(in_features=1024, out_features=512, bias=False)\n",
              "          (project_in): Linear8bitLt(in_features=512, out_features=1024, bias=False)\n",
              "          (layers): ModuleList(\n",
              "            (0-23): 24 x OPTDecoderLayer(\n",
              "              (self_attn): OPTAttention(\n",
              "                (k_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "                (v_proj): lora.Linear8bitLt(\n",
              "                  (base_layer): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.05, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1024, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (q_proj): lora.Linear8bitLt(\n",
              "                  (base_layer): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.05, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1024, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (out_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "              )\n",
              "              (activation_fn): ReLU()\n",
              "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (fc1): Linear8bitLt(in_features=1024, out_features=4096, bias=True)\n",
              "              (fc2): Linear8bitLt(in_features=4096, out_features=1024, bias=True)\n",
              "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (lm_head): Linear(in_features=512, out_features=50272, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from peft import get_peft_model, LoraConfig\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=8,                   # the rank of the adapter, the lower the fewer parameters you'll need to train\n",
        "    lora_alpha=16,         # multiplier, usually 2*r\n",
        "    bias=\"none\",           # BEWARE: training biases *modifies* base model's behavior\n",
        "    lora_dropout=0.05,\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lX5o_I0kGsxn",
      "metadata": {
        "id": "lX5o_I0kGsxn"
      },
      "source": [
        "Notice that the attention layers (`k_proj`, `v_proj`, and `q_proj`) which already were quantized (`Linear8bitLt`), now have a set of several much smaller LoRA-related `Linear` layers attached to them.\n",
        "\n",
        "These extra layers will make the model slightly larger:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "G6EkXP18EQhR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6EkXP18EQhR",
        "outputId": "bc701908-71fd-408d-b0f9-cb907083998c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "362.500096\n"
          ]
        }
      ],
      "source": [
        "print(model.get_memory_footprint()/1e6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Uz2IWEAEHLAP",
      "metadata": {
        "id": "Uz2IWEAEHLAP"
      },
      "source": [
        "But, overall, only a tiny fraction of the total number of parameters is trainable now, thanks to LoRA!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "vNLbOq6GEQhR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNLbOq6GEQhR",
        "outputId": "e2fbc843-0b3c-4856-a386-8b03e5a11db0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.786432 0.2368893467652883\n"
          ]
        }
      ],
      "source": [
        "trainable_parms, tot_parms = model.get_nb_trainable_parameters()\n",
        "print(trainable_parms/1e6, 100*trainable_parms/tot_parms)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o7OblnYAEQhR",
      "metadata": {
        "id": "o7OblnYAEQhR"
      },
      "source": [
        "## Fine-Tuning with SFTTrainer\n",
        "\n",
        "The `SFTTrainer` (Supervised Fine-Tuning Trainer) object takes:\n",
        "- a model\n",
        "- a tokenizer\n",
        "- a dataset\n",
        "- a configuration object\n",
        "\n",
        "We already have the first three elements, let's work on the last one."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eHnCCh1hEQhS",
      "metadata": {
        "id": "eHnCCh1hEQhS"
      },
      "source": [
        "### `SFTConfig`\n",
        "\n",
        "#### Gradient Checkpointing\n",
        "\n",
        "This is an overlooked hero in most tutorials.\n",
        "\n",
        "The memory gains, if the sequences are long (e.g. 1,000 tokens), are HUGE.\n",
        "\n",
        "#### Gradient Accumulation\n",
        "\n",
        "Next to the huge elephant (the LLM) we must be able to fit **at least one data point** in the GPU RAM.\n",
        "\n",
        "A mini-batch of one is no fun, though, so we turn to **gradient accumulation**.\n",
        "\n",
        "The mini-batch size (`per_device_train_batch_size`) will actually stand for a **micro-batch** which works as an intermediate step. After a few micro-batches (`gradient_accumulation_steps`), the model update will be triggered.\n",
        "\n",
        "The effective mini-batch size is: `gradient_accumulation_steps` x `per_device_train_batch_size`\n",
        "\n",
        "#### Auto-find Batch Size\n",
        "\n",
        "Is there anything more annoying than OOM errors? Do you like trying out mini/micro batch sizes on your own? Me neither! If set to `True`, it will start with `per_device_train_batch_size` and, should it result in OOM error, it halves the size and try again until it works.\n",
        "\n",
        "#### Optim\n",
        "\n",
        "The optimizer it should use. We can choose a paged 8-bit optimizer (`\"paged_adamw_8bit\"`) to squeeze the most space out of it. In our case, though, it won't make much of a difference since LoRA reduced the number of trainable parameters to a handful.\n",
        "\n",
        "#### Max Sequence Length\n",
        "\n",
        "The sequence length is one of the main drivers of memory usage, especially since we cannot use Flash Attention.\n",
        "\n",
        "So, we should choose a value that's not much more than what we actually need.\n",
        "\n",
        "How long are our sequences (considering **both** prompt and completion, that is):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "YtHengPcEQhS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518,
          "referenced_widgets": [
            "c9bb75229186405b8165716238678146",
            "57c893b517404f8dbd627b3273f38c0f",
            "350a72a35d8047aeb2dbdd77b4e50144",
            "40debba5a8ff49ceb2f88ecc906bb8be",
            "e78c8042eaaa4148b1b0c5ec5d14afec",
            "3581181d90fb412bb415015da3c68c32",
            "a323180a5a85413997181f85bb368d02",
            "f4d9f26454e54b858151cf47fd430c43",
            "733b54e5563d428b9a05b830ab94d030",
            "c1b723475d34459fb64ee0395aa67a95",
            "1fa1afdb057c42ba95d109ce7b8252eb"
          ]
        },
        "id": "YtHengPcEQhS",
        "outputId": "b2b5c8ae-e9fe-4b29-9991-4236819de2d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/720 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9bb75229186405b8165716238678146"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  5.,  18.,  91.,  55., 224., 136., 128.,  23.,  31.,   9.]),\n",
              " array([10. , 11.5, 13. , 14.5, 16. , 17.5, 19. , 20.5, 22. , 23.5, 25. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.hist(dataset.map(lambda row: {'len': len(row['prompt'].split()) + len(row['completion'].split())})['len'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-XbWZLPXEQhS",
      "metadata": {
        "id": "-XbWZLPXEQhS"
      },
      "source": [
        "The longest sequences have 25 words.\n",
        "\n",
        "That's roughly 30 tokens (as a rule of thumb, **1 token = 0.8 word**).\n",
        "\n",
        "We'll also add some special tokens to it, so it's surely shorter than 40 tokens in total.\n",
        "\n",
        "We may give the user some wiggle room to come up with slightly longer sentences, so let's make it 64 tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "wim0ViZ4EQhT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143,
          "referenced_widgets": [
            "8ff4999069c440af8f4ea4cd183e5c7b",
            "d2b1cef5e1f442b2bee085e1e57c2df1",
            "3633e678e33b4ed7a97d47bc6aed6efb",
            "92e001bfb8194c07a462dbce42f689f8",
            "af05949e15ec4154921cc3c226b67f8c",
            "151c7a530ff64f54be8cb5f7436c7b89",
            "16cd643a704d4ae9b0b9151fbc790e8f",
            "8cd9fb7e4827440990c7eaa6f7fe5345",
            "53ad7a6bd579440c9e795a5ef9eb04b5",
            "d96dd346359741a0a912aaeb87756b4a",
            "a3dac09838ed4cfaa9321ce4e7f5e663"
          ]
        },
        "id": "wim0ViZ4EQhT",
        "outputId": "5cb8f832-08a7-473f-b9d7-84148d66f6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:366: UserWarning: You passed a `dataset_kwargs` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/720 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ff4999069c440af8f4ea4cd183e5c7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:408: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "sft_config = SFTConfig(\n",
        "    gradient_checkpointing=True,    # this saves a LOT of memory\n",
        "    gradient_checkpointing_kwargs={'use_reentrant': False}, # set this to avoid exceptions in newer versions of PyTorch\n",
        "    gradient_accumulation_steps=4,  # actual batch (for updating) is 4x micro-batch size\n",
        "    per_device_train_batch_size=8,  # the initial (micro) batch size to start off with\n",
        "    auto_find_batch_size=True,      # if (micro) batch size would cause OOM, halves its size until it works\n",
        "    optim='paged_adamw_8bit',       # 8-bit Adam optimizer - doesn't help much if you're using LoRA!\n",
        "    max_seq_length=64,\n",
        "    ## These are typical training parameters\n",
        "    num_train_epochs=30,            # 20 epochs take about 10 minutes on Colab's T4 GPU\n",
        "    learning_rate=3e-4,\n",
        "    logging_steps=20,\n",
        "    logging_dir=\"./logs\",\n",
        "    output_dir='./tmp',\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=sft_config,\n",
        "    train_dataset=dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eHBCU9oNEQhT",
      "metadata": {
        "id": "eHBCU9oNEQhT"
      },
      "source": [
        "The `SFTTrainer` had already preprocessed our dataset, so we can peek inside and see how each mini-batch was assembled:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "IqZZaPE5EQhT",
      "metadata": {
        "id": "IqZZaPE5EQhT"
      },
      "outputs": [],
      "source": [
        "dl = trainer.get_train_dataloader()\n",
        "batch = next(iter(dl))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZpN8Q9zPHwMt",
      "metadata": {
        "id": "ZpN8Q9zPHwMt"
      },
      "source": [
        "As it turns out, a mini-batch of eight does fit well into memory. We could have probably used a larger batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "MiSbckeIHm47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiSbckeIHm47",
        "outputId": "a67a33c3-be06-4c9d-a113-0f9e15c48449"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(batch['input_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85A2h7ntH5Lf",
      "metadata": {
        "id": "85A2h7ntH5Lf"
      },
      "source": [
        "Let's check the labels, after all, we didn't provide any, right?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ZyttnYrEH5dx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyttnYrEH5dx",
        "outputId": "9be6fe5d-2202-4733-cbbe-74c47251d307"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([50265, 50265, 50265, 50265, 50265, 50265, 50265, 50265, 50266, 12105,\n",
              "         50118,  1213,   362,    49,  1159,    31,     5,   285,   334,     4,\n",
              "         50267, 50118, 50266,  2401, 33388, 50118,  7605,     5,   285,   334,\n",
              "             6,    49,  1159,    51,   362,     4,   289,   338, 41311,     4,\n",
              "         50267, 50118], device='cuda:0'),\n",
              " tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 50266, 12105,\n",
              "         50118,  1213,   362,    49,  1159,    31,     5,   285,   334,     4,\n",
              "         50267, 50118, 50266,  2401, 33388, 50118,  7605,     5,   285,   334,\n",
              "             6,    49,  1159,    51,   362,     4,   289,   338, 41311,     4,\n",
              "         50267, 50118], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "batch['input_ids'][0], batch['labels'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KJ1jHu9mIyfl",
      "metadata": {
        "id": "KJ1jHu9mIyfl"
      },
      "source": [
        "The labels were added automatically, and they are exactly the same as the inputs (thus making this a case of self-supervised fine-tuning).\n",
        "\n",
        "The shifting of the labels is going to be handled automatically as well, there's no need to be concerned about it.\n",
        "\n",
        "Did you notice there's a difference in the beginning of both sequences? Can you guess which token that is?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "GKtwKecHItQb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GKtwKecHItQb",
        "outputId": "e33f1a0a-cb62-42e2-9919-c02f709190c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|pad|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens(50265)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ue4wpMFyEQhU",
      "metadata": {
        "id": "ue4wpMFyEQhU"
      },
      "source": [
        "### Training\n",
        "\n",
        "Now, we call the `train()` method and wait. It takes around 10 minutes to train for 10 epochs using Colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cglB4p8EQhU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "0cglB4p8EQhU",
        "outputId": "ca4a7850-92ce-439a-c267-e159ca5f3630"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='660' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [660/660 10:52, Epoch 29/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.585300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.208900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.818300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.639800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.564100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.528600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.465000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.447100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.423400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.402400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.388500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.375900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.346200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.328500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.346700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.321300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>1.298300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.293600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>1.275200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.281500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>1.264400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>1.251600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>1.257700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>1.242100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.235600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>1.225000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>1.228700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>1.220800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>1.211800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.217200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>1.202100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>1.196100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>1.207200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=660, training_loss=1.433301151160038, metrics={'train_runtime': 661.2779, 'train_samples_per_second': 32.664, 'train_steps_per_second': 0.998, 'total_flos': 1540201759506432.0, 'train_loss': 1.433301151160038, 'epoch': 29.333333333333332})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "071c2973-6f46-4a64-ae00-a2ee5b6ba72b",
      "metadata": {
        "id": "071c2973-6f46-4a64-ae00-a2ee5b6ba72b"
      },
      "source": [
        "After 10 epochs, the loss should be around 1.4. After 30 epochs. around 1.2."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4f19b3a",
      "metadata": {
        "id": "d4f19b3a"
      },
      "source": [
        "### Loading the Adapter from the Hub\n",
        "\n",
        "I have already trained the model for 30 epochs and pushed it to the hub, so we can try it right away without having to wait for the training process to finish. Moreover, since we modified the tokenizer, I have pushed it to the hub as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "d297b8e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "c9af4331530d4a4c85e894f9f5f913cc",
            "ab44f7a66a004eebbb126ff059ce6cdd",
            "170bbbfc3262419caef76c7c5e07fc10",
            "3e90213422284f6694826dcebf4cc8b5",
            "06eae9e2bd6f4e24b077e9acca2aee5d",
            "16d4e9b1f61547cd8fd0cb8d8ea32af7",
            "3bcf1f7164eb4d479749efda359377a2",
            "f50dfddf6d17411ab7e90b5e17107288",
            "a0375ce3b2284d5f81c8c742f72b1aec",
            "a8bfb4ec965c41dd8a7119553e276d07",
            "e55fc1a877424974833d0d08fad30279",
            "aa23cb62e5bb40ae925b3243abf723f4",
            "49160a2067a945a58b79d08bf20c21ba",
            "e4632315e82646bb86d835be99c2c4ec",
            "aabf6aa0baef420fa44b59205ad96c98",
            "c8325c7924c946d3b8ec9f2c8b12b390",
            "ccd6b13af8e34fb2b4eaa31a66edf46c",
            "6ab762d47e28432e83272e933b3fb125",
            "9369715022c24ac982a5df5e4b74675d",
            "e8a43cf4be2f4b79824b4d813fffca9d",
            "1426230e74c14feb9c804af77dfecb37",
            "f921b67afe0d47bdadecad40c8b2dba1",
            "880e149005674f9c9acf17e6d131e5d3",
            "17d71f10d5054d67bbdfec14afe4ee63",
            "37270a0b117e4fa8a0f85920106e0242",
            "06fe1c73046b45efb10ff65fe25caa33",
            "d389db278d95435f84574c43df99c209",
            "3e2022532517415b9267cad01fb738ed",
            "c66bb27b23614de2b45503f326aaf4c0",
            "f8a754caba3f4341b677c867fa3dfe15",
            "7ce66397ba4f4417b7f740df3566695b",
            "2c15ffe21a0a49cba273c74824470be7",
            "1e51586676fe482e9c467b1ebc4c1b9d",
            "f8c083454f4047f48ffb0e0baf21e8a3",
            "bcc85c1c19df4ca39f49b03ca2b52875",
            "caf40493dff34260a51bb12dac34a866",
            "8c31e076563043d29ef8235a0f2721b4",
            "a93fbbf5759645a08da76d1bf4d08086",
            "ff8eb8447a674b77af9ff9b87c430834",
            "1007e1eadfc841559761910f42f097d0",
            "fd5564c112254b00b6cbe6de7feba6cb",
            "75ae4568ddf54d278fd040217d1e8b16",
            "da1d5aabf1fa4f9793c8ce80a173bc2c",
            "3acd4d4a7bd84256bd91a2b1e8ba9e52",
            "05a9b51f681f4c98bed0f3c995e45e50",
            "382f69e79f7843a0aec4396ce194ef9e",
            "d5315b32d48741baac08f2f6cebeeee1",
            "5f4b50a2c23a40cfbabb90d30068a66a",
            "9693b82ee5a040a98752fe4d47528fdf",
            "4a8e78feeea74360858a20297fe9116f",
            "82bf697795fe40a29fc4987aa76981ba",
            "8add17e5cffb41ab8a25950ea59d50ff",
            "9badf25c29c94ff5965237cfd1b7f753",
            "9456d9ecfbbd4db097847363b4feff91",
            "e0eabf03364f4916874378582ddf99ca",
            "fff047fca0e444cd92fead20daf8020f",
            "4d3ae347811742cb86cf7c0e2494055c",
            "55c467161b5147e786d70e03ae70aefe",
            "00d848baa82947719aeeeac93be33a7d",
            "40aad2a573cc45eca10725b8d9058c98",
            "e9f61a1961714cf8bec9229b831f74bc",
            "debb9416dbcc491a8adb81bdb0dae15b",
            "e5282d13ec50455f804018d78b08051f",
            "4455876da557429d865214bcb37090a7",
            "6c77e2b5b8a54d48958a7af62339c788",
            "45a1c0b38dd74606ab8d191dafd0398c"
          ]
        },
        "id": "d297b8e5",
        "outputId": "15afa8ed-c97f-476f-8052-fc4d4569fa21"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9af4331530d4a4c85e894f9f5f913cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa23cb62e5bb40ae925b3243abf723f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "880e149005674f9c9acf17e6d131e5d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8c083454f4047f48ffb0e0baf21e8a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/71.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05a9b51f681f4c98bed0f3c995e45e50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fff047fca0e444cd92fead20daf8020f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# After training, I pushed it to the hub like this\n",
        "# from huggingface_hub import login\n",
        "# login()\n",
        "# trainer.model.push_to_hub('dvgodoy/opt-350m-lora-yoda')\n",
        "# trainer.tokenizer.push_to_hub('dvgodoy/opt-350m-lora-yoda')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dvgodoy/opt-350m-lora-yoda\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"dvgodoy/opt-350m-lora-yoda\", device_map='auto')\n",
        "# overwriting the model in the trainer as well, so we can save it as if it were fully trained\n",
        "trainer.model = model\n",
        "trainer.tokenizer = tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RZvxYdw0JSWw",
      "metadata": {
        "id": "RZvxYdw0JSWw"
      },
      "source": [
        "## Trying Our Model\n",
        "\n",
        "Now, our model *should* be able to understand the chat template, and produce a Yoda-like sentence as a response to any (short) sentence we provide it.\n",
        "\n",
        "So, the model requires its inputs to be formatted as such. We need to build a list of \"messages\" (only ours, the `user`, in this case) and - literally - **prompt** the model to answer by indicating it is **its turn to write**.\n",
        "\n",
        "This is the purpose of the `add_generation_prompt` argument: it adds `<|im_start|>assistant` to the end of the conversation, so the model can predict the next word (and again and again, until it predicts an `<|endoftext|>` token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "WZpxxClZEQhV",
      "metadata": {
        "id": "WZpxxClZEQhV"
      },
      "outputs": [],
      "source": [
        "def gen_prompt(tokenizer, sentence, add_generation_prompt=True):\n",
        "    converted_sample = [\n",
        "        {\"role\": \"user\", \"content\": sentence},\n",
        "    ]\n",
        "    prompt = tokenizer.apply_chat_template(converted_sample, tokenize=False, add_generation_prompt=True)\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "1TbOURqmEQhV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TbOURqmEQhV",
        "outputId": "02b31057-a910-45fc-ca5b-a82800d56528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>user\n",
            "Do not give up so soon!<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentence = 'Do not give up so soon!'\n",
        "prompt = gen_prompt(tokenizer, sentence)\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u845uOtEKSlp",
      "metadata": {
        "id": "u845uOtEKSlp"
      },
      "source": [
        "The prompt seems about right, let's use it to generate a completion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "sHXe_qB8EQhV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHXe_qB8EQhV",
        "outputId": "eb10cbe8-0025-47ab-ce05-9364f3208323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>user\n",
            "Do not give up so soon!<|im_end|>\n",
            "<|im_start|>assistant\n",
            "So soon, do not give up, you must.<|im_end|>\n"
          ]
        }
      ],
      "source": [
        "print(generate(model, tokenizer, prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CcG_TNuWKWpA",
      "metadata": {
        "id": "CcG_TNuWKWpA"
      },
      "source": [
        "Awesome! It works!\n",
        "\n",
        "If you trained it for 10 epochs only, it works well most of the time. If you train it for longer, say, 30 epochs, it will be even better.\n",
        "\n",
        "Let's try a few more sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "pwmpp1c8EQhW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwmpp1c8EQhW",
        "outputId": "f863ab73-4558-4970-ec95-66d28c2a09df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>user\n",
            "Jump over the lazy fox.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Over the lazy fox, jump, you must.<|im_end|>\n"
          ]
        }
      ],
      "source": [
        "sentence = 'Jump over the lazy fox.'\n",
        "print(generate(model, tokenizer, gen_prompt(tokenizer, sentence)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "OgzPlvweEQhW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgzPlvweEQhW",
        "outputId": "0e37297e-0508-4869-eb52-08499d02e95e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>user\n",
            "The Force is strong in this one!<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Strong in this one, the Force is.<|im_end|>\n"
          ]
        }
      ],
      "source": [
        "sentence = 'The Force is strong in this one!'\n",
        "print(generate(model, tokenizer, gen_prompt(tokenizer, sentence)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "3faO0uMNEQhW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3faO0uMNEQhW",
        "outputId": "c600216d-a133-4846-9042-e28f02917b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>user\n",
            "Fine-tuning LLMs is easy.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Easy, fine-tuning LLMs is.<|im_end|>\n"
          ]
        }
      ],
      "source": [
        "sentence = 'Fine-tuning LLMs is easy.'\n",
        "print(generate(model, tokenizer, gen_prompt(tokenizer, sentence)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ZTz7jIiKae2",
      "metadata": {
        "id": "4ZTz7jIiKae2"
      },
      "source": [
        "We can also try a sentence from the training set itself:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "PXP5GfMiEQhW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXP5GfMiEQhW",
        "outputId": "3a1c98d8-3ee8-48b8-b870-81c02b3d12a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>user\n",
            "Whitings are small fish caught in nets.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "In nets, small fish caught, whitings are.<|im_end|>\n",
            "\n",
            "Completion:\n",
            "Caught in nets, small fish, whitings are. Yes, hrrmmm.\n"
          ]
        }
      ],
      "source": [
        "i = 235\n",
        "print(generate(model, tokenizer, gen_prompt(tokenizer, dataset[i]['prompt'])))\n",
        "print(f\"\\nCompletion:\\n{dataset[i]['completion']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "mtEP-sn6MO0A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtEP-sn6MO0A",
        "outputId": "0c36e688-2b58-46cc-fa9a-69000d95c654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>user\n",
            "The model speaks like Yoda.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Like Yoda, the model speaks.<|im_end|>\n"
          ]
        }
      ],
      "source": [
        "sentence = 'The model speaks like Yoda.'\n",
        "print(generate(model, tokenizer, gen_prompt(tokenizer, sentence)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6yQkOzjKeYV",
      "metadata": {
        "id": "d6yQkOzjKeYV"
      },
      "source": [
        "**Like Yoda, the model speaks. Yes, hrmm.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b4ffc47",
      "metadata": {
        "id": "8b4ffc47"
      },
      "source": [
        "## Saving The Model\n",
        "\n",
        "You may also save both adapter and tokenizer to disk, instead of pushing them to the hub:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "bqqhHTJrMc-U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqqhHTJrMc-U",
        "outputId": "c7634ab0-25a5-4501-b0a6-37dee9c551f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:397: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('yoda_adapter/tokenizer_config.json',\n",
              " 'yoda_adapter/special_tokens_map.json',\n",
              " 'yoda_adapter/vocab.json',\n",
              " 'yoda_adapter/merges.txt',\n",
              " 'yoda_adapter/added_tokens.json',\n",
              " 'yoda_adapter/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# trainer.save_model('yoda_adapter')\n",
        "# it is equivalent to saving both model and tokenizer\n",
        "trainer.model.save_pretrained('yoda_adapter')\n",
        "# if you modified the tokenizer, you need to save it as well\n",
        "trainer.tokenizer.save_pretrained('yoda_adapter')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BONUS\n",
        "\n",
        "### Loading with Resized Embeddings\n",
        "\n",
        "If your embeddings were resized, you'd need to load the base model first, resize its embeddings accordingly, and **only then** load your adapter using `PeftModel.from_pretrained()` instead:"
      ],
      "metadata": {
        "id": "2afp9NqfBdgI"
      },
      "id": "2afp9NqfBdgI"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "056c2b8a-d67f-4a89-a53a-b5e17e4fa6a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "056c2b8a-d67f-4a89-a53a-b5e17e4fa6a9",
        "outputId": "7f555163-d45e-49a8-c690-9169c05bab32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): OPTForCausalLM(\n",
              "      (model): OPTModel(\n",
              "        (decoder): OPTDecoder(\n",
              "          (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
              "          (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
              "          (project_out): Linear(in_features=1024, out_features=512, bias=False)\n",
              "          (project_in): Linear(in_features=512, out_features=1024, bias=False)\n",
              "          (layers): ModuleList(\n",
              "            (0-23): 24 x OPTDecoderLayer(\n",
              "              (self_attn): OPTAttention(\n",
              "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (v_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.05, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1024, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (q_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.05, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1024, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              )\n",
              "              (activation_fn): ReLU()\n",
              "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (lm_head): Linear(in_features=512, out_features=50272, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained('yoda_adapter')\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\", device_map='auto')\n",
        "num_embeddings = base_model.get_input_embeddings().num_embeddings\n",
        "if num_embeddings < len(loaded_tokenizer):\n",
        "  base_model.resize_token_embeddings(len(loaded_tokenizer))\n",
        "model_to_merge = PeftModel.from_pretrained(base_model, 'yoda_adapter')\n",
        "model_to_merge"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merging Adapters\n",
        "\n",
        "It is also possible to merge the adapters into the base model, resulting in what would have been the result of directly fine-tuning the linear layers that were adapted. It is as simgple as calling the (adapted) model's `merge_and_unload()` method:"
      ],
      "metadata": {
        "id": "uVi-hDAQEpap"
      },
      "id": "uVi-hDAQEpap"
    },
    {
      "cell_type": "code",
      "source": [
        "merged_model = model_to_merge.merge_and_unload()\n",
        "merged_model.save_pretrained('yoda_model')\n",
        "merged_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj4L7MrLBpcV",
        "outputId": "ecb2a2ca-983f-4181-8893-4b0a53a18522"
      },
      "id": "Xj4L7MrLBpcV",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OPTForCausalLM(\n",
              "  (model): OPTModel(\n",
              "    (decoder): OPTDecoder(\n",
              "      (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
              "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
              "      (project_out): Linear(in_features=1024, out_features=512, bias=False)\n",
              "      (project_in): Linear(in_features=512, out_features=1024, bias=False)\n",
              "      (layers): ModuleList(\n",
              "        (0-23): 24 x OPTDecoderLayer(\n",
              "          (self_attn): OPTAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): ReLU()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=50272, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take the merged model for a quick spin to make sure it is working fine:"
      ],
      "metadata": {
        "id": "UWUA5sj6FKg7"
      },
      "id": "UWUA5sj6FKg7"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "1a2e7a66-acd7-4836-800d-6c8fc65fd2b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a2e7a66-acd7-4836-800d-6c8fc65fd2b1",
        "outputId": "f1f5ccf1-86d0-4278-e15a-352ea30da4a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>user\n",
            "Jump over the lazy fox.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Over the lazy fox, jump, you must.<|im_end|>\n"
          ]
        }
      ],
      "source": [
        "sentence = 'Jump over the lazy fox.'\n",
        "print(generate(merged_model, tokenizer, gen_prompt(tokenizer, sentence)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sXfb0OTGKvk5",
      "metadata": {
        "id": "sXfb0OTGKvk5"
      },
      "source": [
        "And that's a wrap!\n",
        "\n",
        "Now, it's your time to try and fine-tune your own models!\n",
        "\n",
        "<center><h1>THANK YOU!</h1></center>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9bb75229186405b8165716238678146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57c893b517404f8dbd627b3273f38c0f",
              "IPY_MODEL_350a72a35d8047aeb2dbdd77b4e50144",
              "IPY_MODEL_40debba5a8ff49ceb2f88ecc906bb8be"
            ],
            "layout": "IPY_MODEL_e78c8042eaaa4148b1b0c5ec5d14afec"
          }
        },
        "57c893b517404f8dbd627b3273f38c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3581181d90fb412bb415015da3c68c32",
            "placeholder": "​",
            "style": "IPY_MODEL_a323180a5a85413997181f85bb368d02",
            "value": "Map: 100%"
          }
        },
        "350a72a35d8047aeb2dbdd77b4e50144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4d9f26454e54b858151cf47fd430c43",
            "max": 720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_733b54e5563d428b9a05b830ab94d030",
            "value": 720
          }
        },
        "40debba5a8ff49ceb2f88ecc906bb8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b723475d34459fb64ee0395aa67a95",
            "placeholder": "​",
            "style": "IPY_MODEL_1fa1afdb057c42ba95d109ce7b8252eb",
            "value": " 720/720 [00:00&lt;00:00, 9692.71 examples/s]"
          }
        },
        "e78c8042eaaa4148b1b0c5ec5d14afec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3581181d90fb412bb415015da3c68c32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a323180a5a85413997181f85bb368d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4d9f26454e54b858151cf47fd430c43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "733b54e5563d428b9a05b830ab94d030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1b723475d34459fb64ee0395aa67a95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa1afdb057c42ba95d109ce7b8252eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ff4999069c440af8f4ea4cd183e5c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2b1cef5e1f442b2bee085e1e57c2df1",
              "IPY_MODEL_3633e678e33b4ed7a97d47bc6aed6efb",
              "IPY_MODEL_92e001bfb8194c07a462dbce42f689f8"
            ],
            "layout": "IPY_MODEL_af05949e15ec4154921cc3c226b67f8c"
          }
        },
        "d2b1cef5e1f442b2bee085e1e57c2df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_151c7a530ff64f54be8cb5f7436c7b89",
            "placeholder": "​",
            "style": "IPY_MODEL_16cd643a704d4ae9b0b9151fbc790e8f",
            "value": "Map: 100%"
          }
        },
        "3633e678e33b4ed7a97d47bc6aed6efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cd9fb7e4827440990c7eaa6f7fe5345",
            "max": 720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53ad7a6bd579440c9e795a5ef9eb04b5",
            "value": 720
          }
        },
        "92e001bfb8194c07a462dbce42f689f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d96dd346359741a0a912aaeb87756b4a",
            "placeholder": "​",
            "style": "IPY_MODEL_a3dac09838ed4cfaa9321ce4e7f5e663",
            "value": " 720/720 [00:00&lt;00:00, 5281.03 examples/s]"
          }
        },
        "af05949e15ec4154921cc3c226b67f8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "151c7a530ff64f54be8cb5f7436c7b89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16cd643a704d4ae9b0b9151fbc790e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cd9fb7e4827440990c7eaa6f7fe5345": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ad7a6bd579440c9e795a5ef9eb04b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d96dd346359741a0a912aaeb87756b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3dac09838ed4cfaa9321ce4e7f5e663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9af4331530d4a4c85e894f9f5f913cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab44f7a66a004eebbb126ff059ce6cdd",
              "IPY_MODEL_170bbbfc3262419caef76c7c5e07fc10",
              "IPY_MODEL_3e90213422284f6694826dcebf4cc8b5"
            ],
            "layout": "IPY_MODEL_06eae9e2bd6f4e24b077e9acca2aee5d"
          }
        },
        "ab44f7a66a004eebbb126ff059ce6cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16d4e9b1f61547cd8fd0cb8d8ea32af7",
            "placeholder": "​",
            "style": "IPY_MODEL_3bcf1f7164eb4d479749efda359377a2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "170bbbfc3262419caef76c7c5e07fc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f50dfddf6d17411ab7e90b5e17107288",
            "max": 1368,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0375ce3b2284d5f81c8c742f72b1aec",
            "value": 1368
          }
        },
        "3e90213422284f6694826dcebf4cc8b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8bfb4ec965c41dd8a7119553e276d07",
            "placeholder": "​",
            "style": "IPY_MODEL_e55fc1a877424974833d0d08fad30279",
            "value": " 1.37k/1.37k [00:00&lt;00:00, 63.2kB/s]"
          }
        },
        "06eae9e2bd6f4e24b077e9acca2aee5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d4e9b1f61547cd8fd0cb8d8ea32af7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bcf1f7164eb4d479749efda359377a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f50dfddf6d17411ab7e90b5e17107288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0375ce3b2284d5f81c8c742f72b1aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8bfb4ec965c41dd8a7119553e276d07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e55fc1a877424974833d0d08fad30279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa23cb62e5bb40ae925b3243abf723f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49160a2067a945a58b79d08bf20c21ba",
              "IPY_MODEL_e4632315e82646bb86d835be99c2c4ec",
              "IPY_MODEL_aabf6aa0baef420fa44b59205ad96c98"
            ],
            "layout": "IPY_MODEL_c8325c7924c946d3b8ec9f2c8b12b390"
          }
        },
        "49160a2067a945a58b79d08bf20c21ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccd6b13af8e34fb2b4eaa31a66edf46c",
            "placeholder": "​",
            "style": "IPY_MODEL_6ab762d47e28432e83272e933b3fb125",
            "value": "vocab.json: 100%"
          }
        },
        "e4632315e82646bb86d835be99c2c4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9369715022c24ac982a5df5e4b74675d",
            "max": 798293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8a43cf4be2f4b79824b4d813fffca9d",
            "value": 798293
          }
        },
        "aabf6aa0baef420fa44b59205ad96c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1426230e74c14feb9c804af77dfecb37",
            "placeholder": "​",
            "style": "IPY_MODEL_f921b67afe0d47bdadecad40c8b2dba1",
            "value": " 798k/798k [00:00&lt;00:00, 936kB/s]"
          }
        },
        "c8325c7924c946d3b8ec9f2c8b12b390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccd6b13af8e34fb2b4eaa31a66edf46c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ab762d47e28432e83272e933b3fb125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9369715022c24ac982a5df5e4b74675d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a43cf4be2f4b79824b4d813fffca9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1426230e74c14feb9c804af77dfecb37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f921b67afe0d47bdadecad40c8b2dba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "880e149005674f9c9acf17e6d131e5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17d71f10d5054d67bbdfec14afe4ee63",
              "IPY_MODEL_37270a0b117e4fa8a0f85920106e0242",
              "IPY_MODEL_06fe1c73046b45efb10ff65fe25caa33"
            ],
            "layout": "IPY_MODEL_d389db278d95435f84574c43df99c209"
          }
        },
        "17d71f10d5054d67bbdfec14afe4ee63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e2022532517415b9267cad01fb738ed",
            "placeholder": "​",
            "style": "IPY_MODEL_c66bb27b23614de2b45503f326aaf4c0",
            "value": "merges.txt: 100%"
          }
        },
        "37270a0b117e4fa8a0f85920106e0242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8a754caba3f4341b677c867fa3dfe15",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ce66397ba4f4417b7f740df3566695b",
            "value": 456318
          }
        },
        "06fe1c73046b45efb10ff65fe25caa33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c15ffe21a0a49cba273c74824470be7",
            "placeholder": "​",
            "style": "IPY_MODEL_1e51586676fe482e9c467b1ebc4c1b9d",
            "value": " 456k/456k [00:00&lt;00:00, 1.06MB/s]"
          }
        },
        "d389db278d95435f84574c43df99c209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e2022532517415b9267cad01fb738ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c66bb27b23614de2b45503f326aaf4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8a754caba3f4341b677c867fa3dfe15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ce66397ba4f4417b7f740df3566695b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c15ffe21a0a49cba273c74824470be7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e51586676fe482e9c467b1ebc4c1b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8c083454f4047f48ffb0e0baf21e8a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcc85c1c19df4ca39f49b03ca2b52875",
              "IPY_MODEL_caf40493dff34260a51bb12dac34a866",
              "IPY_MODEL_8c31e076563043d29ef8235a0f2721b4"
            ],
            "layout": "IPY_MODEL_a93fbbf5759645a08da76d1bf4d08086"
          }
        },
        "bcc85c1c19df4ca39f49b03ca2b52875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff8eb8447a674b77af9ff9b87c430834",
            "placeholder": "​",
            "style": "IPY_MODEL_1007e1eadfc841559761910f42f097d0",
            "value": "tokenizer.json: 100%"
          }
        },
        "caf40493dff34260a51bb12dac34a866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd5564c112254b00b6cbe6de7feba6cb",
            "max": 2109135,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75ae4568ddf54d278fd040217d1e8b16",
            "value": 2109135
          }
        },
        "8c31e076563043d29ef8235a0f2721b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da1d5aabf1fa4f9793c8ce80a173bc2c",
            "placeholder": "​",
            "style": "IPY_MODEL_3acd4d4a7bd84256bd91a2b1e8ba9e52",
            "value": " 2.11M/2.11M [00:01&lt;00:00, 1.98MB/s]"
          }
        },
        "a93fbbf5759645a08da76d1bf4d08086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff8eb8447a674b77af9ff9b87c430834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1007e1eadfc841559761910f42f097d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd5564c112254b00b6cbe6de7feba6cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75ae4568ddf54d278fd040217d1e8b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da1d5aabf1fa4f9793c8ce80a173bc2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3acd4d4a7bd84256bd91a2b1e8ba9e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05a9b51f681f4c98bed0f3c995e45e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_382f69e79f7843a0aec4396ce194ef9e",
              "IPY_MODEL_d5315b32d48741baac08f2f6cebeeee1",
              "IPY_MODEL_5f4b50a2c23a40cfbabb90d30068a66a"
            ],
            "layout": "IPY_MODEL_9693b82ee5a040a98752fe4d47528fdf"
          }
        },
        "382f69e79f7843a0aec4396ce194ef9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a8e78feeea74360858a20297fe9116f",
            "placeholder": "​",
            "style": "IPY_MODEL_82bf697795fe40a29fc4987aa76981ba",
            "value": "added_tokens.json: 100%"
          }
        },
        "d5315b32d48741baac08f2f6cebeeee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8add17e5cffb41ab8a25950ea59d50ff",
            "max": 71,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9badf25c29c94ff5965237cfd1b7f753",
            "value": 71
          }
        },
        "5f4b50a2c23a40cfbabb90d30068a66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9456d9ecfbbd4db097847363b4feff91",
            "placeholder": "​",
            "style": "IPY_MODEL_e0eabf03364f4916874378582ddf99ca",
            "value": " 71.0/71.0 [00:00&lt;00:00, 1.74kB/s]"
          }
        },
        "9693b82ee5a040a98752fe4d47528fdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a8e78feeea74360858a20297fe9116f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82bf697795fe40a29fc4987aa76981ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8add17e5cffb41ab8a25950ea59d50ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9badf25c29c94ff5965237cfd1b7f753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9456d9ecfbbd4db097847363b4feff91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0eabf03364f4916874378582ddf99ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fff047fca0e444cd92fead20daf8020f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d3ae347811742cb86cf7c0e2494055c",
              "IPY_MODEL_55c467161b5147e786d70e03ae70aefe",
              "IPY_MODEL_00d848baa82947719aeeeac93be33a7d"
            ],
            "layout": "IPY_MODEL_40aad2a573cc45eca10725b8d9058c98"
          }
        },
        "4d3ae347811742cb86cf7c0e2494055c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9f61a1961714cf8bec9229b831f74bc",
            "placeholder": "​",
            "style": "IPY_MODEL_debb9416dbcc491a8adb81bdb0dae15b",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "55c467161b5147e786d70e03ae70aefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5282d13ec50455f804018d78b08051f",
            "max": 552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4455876da557429d865214bcb37090a7",
            "value": 552
          }
        },
        "00d848baa82947719aeeeac93be33a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c77e2b5b8a54d48958a7af62339c788",
            "placeholder": "​",
            "style": "IPY_MODEL_45a1c0b38dd74606ab8d191dafd0398c",
            "value": " 552/552 [00:00&lt;00:00, 14.0kB/s]"
          }
        },
        "40aad2a573cc45eca10725b8d9058c98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9f61a1961714cf8bec9229b831f74bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "debb9416dbcc491a8adb81bdb0dae15b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5282d13ec50455f804018d78b08051f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4455876da557429d865214bcb37090a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c77e2b5b8a54d48958a7af62339c788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45a1c0b38dd74606ab8d191dafd0398c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}